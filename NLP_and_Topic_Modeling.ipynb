{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xp3LTq59E8UK"
      },
      "source": [
        "# Natural Language Processing and Topic Modeling on Interview Response Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nc9DK62BE8UP"
      },
      "source": [
        "# Part 1: Load Data & Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjdBV8gGE8UQ",
        "outputId": "9fdf1092-1513-4570-a17f-3f56615f324c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIj2Z8T70FZD",
        "outputId": "2f50e7fe-d2f0-4f48-e32f-b542820f6010"
      },
      "outputs": [],
      "source": [
        "# Load data into dataframe\n",
        "df = pd.read_csv('data.tsv', sep='\\t', error_bad_lines=False) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "oVIWPym-8MnJ",
        "outputId": "d3c59217-a9ca-4aa5-ceab-3ad377240c15"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQHXofmN8U7T",
        "outputId": "8e1de2d8-a9a5-44ae-85ed-374d75758082"
      },
      "outputs": [],
      "source": [
        "# Checking if there is any missing value\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoRSRJzZA7eT"
      },
      "outputs": [],
      "source": [
        "# Remove missing value\n",
        "df.dropna(subset=['missing_column'],inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbRq4wqlpV_s"
      },
      "outputs": [],
      "source": [
        "df.reset_index(inplace=True, drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDJY4z3qoB77",
        "outputId": "51b2ccce-91b2-44c7-e727-70fa9ab4aeb6"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VbKDogiW79a6"
      },
      "outputs": [],
      "source": [
        "# training data\n",
        "# use the first 2000 data as our training data\n",
        "data = df.loc[:1999, 'response_body'].tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQ4KGnVeE8UX"
      },
      "source": [
        "# Part 2: Tokenizing and Stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gSwiUBRE8UY",
        "outputId": "3a569c31-ce45-4514-a363-7d9574ed5acd"
      },
      "outputs": [],
      "source": [
        "# Load stopwords and stemmer function from NLTK library.\n",
        "# Use nltk's English stopwords.\n",
        "stopwords = nltk.corpus.stopwords.words('english') \n",
        "stopwords.append(\"'s\") \n",
        "stopwords.append(\"'m\")\n",
        "stopwords.append(\"br\") \n",
        "stopwords.append(\"watch\") \n",
        "\n",
        "print (\"We use \" + str(len(stopwords)) + \" stop-words from nltk library.\")\n",
        "print (stopwords[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e50130X8E8Uc"
      },
      "outputs": [],
      "source": [
        "# Use our defined functions to analyze (i.e. tokenize, stem) our responses.\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "# from nltk.stem import WordNetLemmatizer \n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "# tokenization and stemming\n",
        "def tokenization_and_stemming(text): \n",
        "    tokens = []   \n",
        "    for word in nltk.word_tokenize(text):\n",
        "        if word.lower() not in stopwords:\n",
        "            tokens.append(word.lower())\n",
        "\n",
        "    filtered_tokens = []\n",
        "    \n",
        "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
        "    for token in tokens:\n",
        "        if token.isalpha():\n",
        "            filtered_tokens.append(token)\n",
        "     \n",
        "    # stemming\n",
        "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
        "    return stems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "QAWdFqL5E8Uo"
      },
      "source": [
        "# Part 3: TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLPTxSvb9wzT"
      },
      "source": [
        "In this part, I will use the TfidfVectorizer() from the sklearn library to create the tf-idf matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-XH7R4pE8Up",
        "outputId": "6055d1d2-f1d2-46cf-da2b-268506f2864f"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# define vectorizer parameters\n",
        "# max_df : maximum document frequency for the given word\n",
        "# min_df : minimum document frequency for the given word\n",
        "# max_features: maximum number of words\n",
        "# use_idf: if not true, we only calculate tf\n",
        "# stop_words : built-in stop words\n",
        "# tokenizer: how to tokenize the document\n",
        "# ngram_range: (min_value, max_value), eg. (1, 3) means the result will include 1-gram, 2-gram, 3-gram\n",
        "tfidf_model = TfidfVectorizer(max_df=0.99, max_features=1000,\n",
        "                                 min_df=0.01, stop_words='english',\n",
        "                                 use_idf=True, tokenizer=tokenization_and_stemming, ngram_range=(1,1))\n",
        "\n",
        "tfidf_matrix = tfidf_model.fit_transform(data) #fit the vectorizer to synopses\n",
        "\n",
        "print (\"In total, there are \" + str(tfidf_matrix.shape[0]) + \\\n",
        "      \" responses and \" + str(tfidf_matrix.shape[1]) + \" terms.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VpryOuvM9jV",
        "outputId": "c5dbc8d4-30bf-49f2-e0ea-ec87020c9fa6"
      },
      "outputs": [],
      "source": [
        "tfidf_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLdKk6n-E8Uw",
        "outputId": "d28ab550-1bc9-47d6-ea6a-fe277c2af179"
      },
      "outputs": [],
      "source": [
        "# Save the terms identified by TF-IDF. \n",
        "# words\n",
        "tf_selected_words = tfidf_model.get_feature_names()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mWvzNWQFB26",
        "outputId": "afcb04b1-b357-437d-db91-71942bd453ba"
      },
      "outputs": [],
      "source": [
        "# print out words\n",
        "tf_selected_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEcwtws5E8U8"
      },
      "source": [
        "# Part 4: K-means clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nww_RqWe_2Ar"
      },
      "source": [
        "In this part, I will perform the K-means algorithm to find out possible clusters in our responses dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "-Fk2YbWf_iqI",
        "outputId": "65189467-4f5f-4240-b254-33980426dc17"
      },
      "outputs": [],
      "source": [
        "# Use Elbow Method to find the optimal number of clusters\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.style as style\n",
        "\n",
        "range_n_clusters = [1, 2, 3, 4, 5, 6,7,8,9,10]\n",
        "avg_distance=[]\n",
        "for n_clusters in range_n_clusters:\n",
        "  clusterer = KMeans(n_clusters=n_clusters, random_state=42).fit(tfidf_matrix)\n",
        "  avg_distance.append(clusterer.inertia_)\n",
        "\n",
        "style.use(\"fivethirtyeight\")\n",
        "plt.plot(range_n_clusters, avg_distance)\n",
        "plt.xlabel(\"Number of Clusters (k)\")\n",
        "plt.ylabel(\"Distance\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pq8efnLzBzrR"
      },
      "source": [
        "From the plot above, we can see that after 5, the downward trend is not that great as less than 5. So I decide to use 5 as the number of clusters in the kmeans."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGs4aIIME8U_"
      },
      "outputs": [],
      "source": [
        "# Analyze K-means Result\n",
        "\n",
        "# k-means clustering\n",
        "from sklearn.cluster import KMeans\n",
        "num_clusters = 5\n",
        "km = KMeans(n_clusters=num_clusters)\n",
        "km.fit(tfidf_matrix)\n",
        "clusters = km.labels_.tolist()\n",
        "\n",
        "# create DataFrame films from all of the input files.\n",
        "product = { 'response': df[:2000].response_body, 'cluster': clusters}\n",
        "frame = pd.DataFrame(product, columns = ['response', 'cluster'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "APmEUmm6E8VC",
        "outputId": "41e18f09-8e90-4024-b9f1-b6853d1d3963"
      },
      "outputs": [],
      "source": [
        "frame.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "Ht1SbbOSE8VE",
        "outputId": "7c5b76ab-aac9-4b4e-9bab-9d966f2edcaa"
      },
      "outputs": [],
      "source": [
        "print (\"Number of responses included in each cluster:\")\n",
        "frame['cluster'].value_counts().to_frame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phDfUdh5qL9G",
        "outputId": "036232e3-bc7d-44ad-bf45-d1d6fb194f01"
      },
      "outputs": [],
      "source": [
        "km.cluster_centers_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQg0CF11chKK",
        "outputId": "15ce3d63-5a3b-4c2b-c3db-e46f5ee38921"
      },
      "outputs": [],
      "source": [
        "print (\"<Document clustering result by K-means>\")\n",
        "\n",
        "#km.cluster_centers_ denotes the importances of each items in centroid.\n",
        "#We need to sort it in decreasing-order and get the top k items.\n",
        "order_centroids = km.cluster_centers_.argsort()[:, ::-1] \n",
        "\n",
        "Cluster_keywords_summary = {}\n",
        "for i in range(num_clusters):\n",
        "    print (\"Cluster \" + str(i) + \" words:\", end='')\n",
        "    Cluster_keywords_summary[i] = []\n",
        "    for ind in order_centroids[i, :6]: #replace 6 with n words per cluster\n",
        "        Cluster_keywords_summary[i].append(tf_selected_words[ind])\n",
        "        print (tf_selected_words[ind] + \",\", end='')\n",
        "    print ()\n",
        "    \n",
        "    cluster_responses = frame[frame.cluster==i].response.tolist()\n",
        "    print (\"Cluster \" + str(i) + \" responses (\" + str(len(cluster_responses)) + \" ) \")\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670
        },
        "id": "WHsDrz4yKD-2",
        "outputId": "17dc0d6e-2c1f-46b8-a455-c1a99bb20287"
      },
      "outputs": [],
      "source": [
        "# Plot the kmeans result\n",
        "from sklearn.decomposition import KernelPCA\n",
        "import seaborn as sns\n",
        "pca = KernelPCA(n_components=5)\n",
        "tfidf_matrix_np=tfidf_matrix.toarray()\n",
        "X = pca.fit_transform(tfidf_matrix)\n",
        "xs, ys = X[:, 0], X[:,1]\n",
        "pca_df = pd.DataFrame(dict(x = xs, y = ys, Cluster = clusters ))\n",
        "plt.subplots(figsize=(16,9))\n",
        "sns.scatterplot('x', 'y', data=pca_df, hue='Cluster')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPj5X7rrSbz-"
      },
      "source": [
        "From the plot above we can see that cluster 4 contains more negative responses while cluster 2 contains more positive responses. The responses in cluster 0 are more neutral."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYOZXL53E8VV"
      },
      "source": [
        "# Part 5: Topic Modeling - Latent Dirichlet Allocation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBPVbFNFE8VW"
      },
      "outputs": [],
      "source": [
        "# Use LDA for clustering\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "lda = LatentDirichletAllocation(n_components=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PU80SW391II",
        "outputId": "ffc95909-445d-4cae-b38d-a31d6c04b37c"
      },
      "outputs": [],
      "source": [
        "# document topic matrix for tfidf_matrix_lda\n",
        "lda_output = lda.fit_transform(tfidf_matrix)\n",
        "print(lda_output.shape)\n",
        "print(lda_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCJs3lBz90vY",
        "outputId": "72452a5d-258e-4c69-b2bc-598e2dcabd4c",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# topics and words matrix\n",
        "topic_word = lda.components_\n",
        "print(topic_word.shape)\n",
        "print(topic_word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "xCEVfJS5AEgx",
        "outputId": "12bb5ddf-518c-4c14-e0b4-124a6dce6096"
      },
      "outputs": [],
      "source": [
        "# column names\n",
        "topic_names = [\"Topic\" + str(i) for i in range(lda.n_components)]\n",
        "\n",
        "# index names\n",
        "doc_names = [\"Doc\" + str(i) for i in range(len(data))]\n",
        "\n",
        "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns=topic_names, index=doc_names)\n",
        "\n",
        "# get dominant topic for each document\n",
        "topic = np.argmax(df_document_topic.values, axis=1)\n",
        "df_document_topic['topic'] = topic\n",
        "\n",
        "df_document_topic.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "InPLDW7kBSOc",
        "outputId": "b6053b42-a71b-4d9c-f28f-1038e1435a5c"
      },
      "outputs": [],
      "source": [
        "df_document_topic['topic'].value_counts().to_frame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "_yLe_RFHCz0a",
        "outputId": "a733f89e-140b-44e9-f8cc-13c86d220624"
      },
      "outputs": [],
      "source": [
        "print(lda.components_)\n",
        "df_topic_words = pd.DataFrame(lda.components_)\n",
        "df_topic_words.columns = tfidf_model.get_feature_names()\n",
        "df_topic_words.index = topic_names\n",
        "df_topic_words.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "gbU9U8V-DFDX",
        "outputId": "bd34a93f-3a1b-4b9d-a826-b425c969aaf2"
      },
      "outputs": [],
      "source": [
        "# print top n keywords for each topic\n",
        "def print_topic_words(tfidf_model, lda_model, n_words):\n",
        "    words = np.array(tfidf_model.get_feature_names())\n",
        "    topic_words = []\n",
        "    for topic_words_weights in lda_model.components_:\n",
        "        top_words = topic_words_weights.argsort()[::-1][:n_words]\n",
        "        topic_words.append(words.take(top_words))\n",
        "    return topic_words\n",
        "\n",
        "topic_keywords = print_topic_words(tfidf_model=tfidf_model, lda_model=lda, n_words=15)        \n",
        "\n",
        "df_topic_words = pd.DataFrame(topic_keywords)\n",
        "df_topic_words.columns = ['Word '+str(i) for i in range(df_topic_words.shape[1])]\n",
        "df_topic_words.index = ['Topic '+str(i) for i in range(df_topic_words.shape[0])]\n",
        "df_topic_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fQHSr36TJVd"
      },
      "source": [
        "# Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMDDUbzjTLXT"
      },
      "source": [
        "K-means has some limitations. It is very sensitive to outliers. It can produce very small clusters corresponding to outliers. And K-means also has difficulties with clusters of different sizes and densities. \n",
        "\n",
        "Latent Dirichlet allocation (LDA) is a generative statistical model that allows sets of observations to be explained by unobserved groups that explain why some parts of the data are similar. The LDA model is highly modular and can, therefore, be easily extended. The main field of interest is modeling relations between topics. In this task, LDA did a better job of clustering the responses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Unsupervised Learning Project.ipynb_vicky_github",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
